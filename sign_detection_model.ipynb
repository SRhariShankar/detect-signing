{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfDKvi3knfBs"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "import shutil\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras. preprocessing import image\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs_9b9N6HCvj",
        "outputId": "03626787-e5b7-47b2-d40e-a46ccd30f0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout"
      ],
      "metadata": {
        "id": "yTsLP2LnoLhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/Colab Notebooks/data.zip\" -d \"/content/drive/MyDrive/DL\" "
      ],
      "metadata": {
        "id": "p7zpaBcto3bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "20Dq-USEsoF_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dfd8b63c-02ed-4688-f890-a30f050f6449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_gen=ImageDataGenerator(rescale=1/255)\n",
        "test_data=test_data_gen.flow_from_directory('/content/drive/MyDrive/DL/val',\n",
        "                                          batch_size=64,\n",
        "                                          target_size=(256,256),\n",
        "                                          class_mode='binary')\n",
        "\n",
        "train_data_gen=ImageDataGenerator(rescale=1/255)\n",
        "train_data=train_data_gen.flow_from_directory('//content/drive/MyDrive/DL/train',\n",
        "                                           batch_size=64,\n",
        "                                           target_size=(256,256),\n",
        "                                           class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zmt0_y8st0z",
        "outputId": "ccf60df7-86ab-404b-a07f-c33ee21aa8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 46978 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(filters=152, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.Conv2D(filters=152, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "    layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(1500, activation='relu'),\n",
        "    layers.Dense(2000, activation='relu'),\n",
        "    \n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "    \n",
        "])"
      ],
      "metadata": {
        "id": "K1Syt3qd05S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "n6_bMVgN44Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.summary()"
      ],
      "metadata": {
        "id": "lw2gm-335TI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(train_data, epochs =10,steps_per_epoch=100)"
      ],
      "metadata": {
        "id": "Ei8VxbscFwVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f5e91b-c5fd-4d3d-8e8d-6e030ba234c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 29s 274ms/step - loss: 0.6657 - accuracy: 0.5753\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.5132 - accuracy: 0.7670\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 29s 283ms/step - loss: 0.4691 - accuracy: 0.7931\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 28s 275ms/step - loss: 0.4537 - accuracy: 0.8102\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 28s 276ms/step - loss: 0.4164 - accuracy: 0.8341\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 28s 276ms/step - loss: 0.3770 - accuracy: 0.8481\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.3588 - accuracy: 0.8642\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.3307 - accuracy: 0.8720\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.3112 - accuracy: 0.8786\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.2793 - accuracy: 0.8933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4454219290>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.save('/content/drive/MyDrive/DL/Model.h5')"
      ],
      "metadata": {
        "id": "utkYmAbUjIU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ibfW1qdIBpOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tensorflow.keras.models.load_model('/content/drive/MyDrive/DL/Model.h5')"
      ],
      "metadata": {
        "id": "NW5tU2k7BpLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "-_WKgs1bBqAm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l2MYyS0gBpII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/Colab Notebooks/Colab_Notebooks/inference.zip\" -d \"/content/drive/MyDrive/DL\""
      ],
      "metadata": {
        "id": "ZRhYSyzRv7_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rescale=ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "QoPs14k-BLyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer_dataset=rescale.flow_from_directory(\"/content/drive/MyDrive/DL/infer\",target_size=(256,256),batch_size=64, class_mode='binary',shuffle=\"True\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WjXBcZuAaIz",
        "outputId": "de7b2e0c-1302-47a2-8e52-3690480a9ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(infer_dataset)"
      ],
      "metadata": {
        "id": "1tqxr4dwvg0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b57d73-47b6-4a94-d07b-fa4295196132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 21s 210ms/step - loss: 0.1276 - accuracy: 0.9622\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1275905817747116, 0.9621666669845581]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}